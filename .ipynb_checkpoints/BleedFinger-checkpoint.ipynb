{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "64052457-357d-4e9a-8597-d502ed22ab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Embedding, Layer, MultiHeadAttention, Input, Dense, LayerNormalization, TextVectorization, GlobalAveragePooling1D, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import convert_to_tensor, string, float32, shape, range, reshape\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, RocCurveDisplay, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f4911ac8-9692-4f06-b29d-c0a0c98943f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"full_clean_checkpoint.csv\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.article, df.label, \n",
    "                                                     test_size=0.2, stratify=df.label, \n",
    "                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1a7ff1ea-1c9f-4620-8677-4aeca545aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_proc_new(data):\n",
    "    if not isinstance(data, str):\n",
    "        return None  # Mark for removal later\n",
    "\n",
    "    try:\n",
    "        data = data.translate(str.maketrans('', '', s.punctuation))\n",
    "        data = data.lower()\n",
    "\n",
    "        stems = stemmer_tl.get_stems(data)\n",
    "        if not isinstance(stems, list):\n",
    "            return None  # Mark for removal\n",
    "\n",
    "        data_stem = []\n",
    "        for word in stems:\n",
    "            if isinstance(word, str) and word:\n",
    "                lemma = simplemma.lemmatize(word, lang='en', greedy=True)\n",
    "                data_stem.append(lemma)\n",
    "\n",
    "        data_sw_tl = [word for word in data_stem if word not in stopwords_tl]\n",
    "        data_sw_en = [word for word in data_sw_tl if word not in stopwords_en]\n",
    "        data_final = \" \".join(data_sw_en)\n",
    "\n",
    "        return data_final\n",
    "\n",
    "    except Exception as e:\n",
    "        # Optional: log or print for debugging\n",
    "        print(f\"Error processing: {data.index} | Exception: {e}\")\n",
    "        return None  # Mark for removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9e869afe-c029-4a8a-964e-5a38c78ddc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingLayer(Layer):\n",
    "    \n",
    "    def __init__(self, seq_length, dict_size, richness):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.WordEmbedding =  Embedding(input_dim = dict_size, output_dim=richness)\n",
    "        self.Pos_Embedding =  Embedding(input_dim = seq_length, output_dim=richness)\n",
    "\n",
    "    def call(self, tokens):\n",
    "        sequence_length = shape(tokens)[-1]\n",
    "        all_positions =  range(start=0, limit=seq_length, delta=1)\n",
    "        pos_enc = self.Pos_Embedding(all_positions)\n",
    "        word_enc = self.WordEmbedding(tokens)\n",
    "        return pos_enc + word_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7e8ee4b0-8fb4-4020-afca-a9909354816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodingLayer(Layer):\n",
    "    \n",
    "    def __init__(self, Multi_heads, Tot_dense, richness):\n",
    "        super(EncodingLayer, self).__init__()\n",
    "        self.MultiHead =  MultiHeadAttention(num_heads = Multi_heads, key_dim = richness)\n",
    "        self.MiniMLP =  Sequential([Dense(Tot_dense, activation='relu'), Dense(richness)])\n",
    "        self.NormalizeLayer = LayerNormalization()\n",
    "         \n",
    "    def call(self, inputs):\n",
    "        Multihead_output = self.MultiHead(inputs, inputs)\n",
    "        normalize_multihead =  self.NormalizeLayer(inputs + Multihead_output)\n",
    "        MiniMLP_out = self.MiniMLP(normalize_multihead)\n",
    "        final_output = self.NormalizeLayer(inputs + MiniMLP_out)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "47697a6c-8048-41fd-9330-b7875d1065c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2649    usapusapan social medium umanoy gaya katawan t...\n",
       "2800    akala daw testigo luhod suspek harap altar dal...\n",
       "570     bitbit mandaragat espanyol pinya lakbay upan i...\n",
       "2452    consider filing legal action impose sanction p...\n",
       "1810    sapul department environment natural resource ...\n",
       "                              ...                        \n",
       "1795    sitting let pass ganti gawa san kongresista si...\n",
       "2023    tila naghuhurumentado lang militant estudyante...\n",
       "2139    tawag san opisyal baha katolika netizen bawasb...\n",
       "2893    bula 6 gamit publiko locallymake hybrid electr...\n",
       "2733    general ronald bato dela rosa napahagolgol senado\n",
       "Name: article, Length: 2527, dtype: object"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "f2291f00-09fc-4b08-bb44-4eda6f447906",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Vectorization\n",
    "vocab_size= 3000\n",
    "seq_length = 300\n",
    "train_X_tensor = convert_to_tensor(X_train)\n",
    "vectorizer = TextVectorization(output_sequence_length = seq_length, max_tokens=30)\n",
    "\n",
    "vectorizer.adapt(train_X_tensor)\n",
    "\n",
    "train_X_tensors = convert_to_tensor(X_train, dtype=string)\n",
    "train_X_vector = vectorizer(train_X_tensors)\n",
    "\n",
    "test_X_tensors = convert_to_tensor(X_test, dtype=string)\n",
    "test_X_vector = vectorizer(test_X_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e36dab5f-18fd-4f7e-9ee0-1126dea7de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "richness =  64\n",
    "heads = 3\n",
    "total_dense = 20\n",
    "\n",
    "embedding = EmbeddingLayer(seq_length, vocab_size, richness)\n",
    "encoding = EncodingLayer(Multi_heads = heads, Tot_dense = total_dense, richness=richness)\n",
    "\n",
    "inputs = Input(shape=(seq_length, ))\n",
    "emb = embedding(inputs)\n",
    "enc = encoding(emb)\n",
    "pool = GlobalAveragePooling1D()(enc)\n",
    "d = Dense(5, activation='relu')(pool)\n",
    "outputs = Dense(1, activation = 'sigmoid')(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fb8c431c-f9ea-4af3-a676-8d7f2069e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_39\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_39\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_layer_23              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">211,200</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EmbeddingLayer</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoding_layer_22               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">58,240</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EncodingLayer</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_17     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_36 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_layer_23              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m211,200\u001b[0m │\n",
       "│ (\u001b[38;5;33mEmbeddingLayer\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ encoding_layer_22               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m58,240\u001b[0m │\n",
       "│ (\u001b[38;5;33mEncodingLayer\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_17     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_74 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m325\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_75 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">269,771</span> (1.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m269,771\u001b[0m (1.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">269,771</span> (1.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m269,771\u001b[0m (1.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformer = Model(inputs=inputs, outputs=outputs)\n",
    "transformer.compile(optimizer=Adam(learning_rate = 3e-4), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "1a432012-cda3-4ceb-bde2-dde28d7802e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - accuracy: 0.7312 - loss: 0.6001 - val_accuracy: 0.7668 - val_loss: 0.5160\n",
      "Epoch 2/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.7701 - loss: 0.5011 - val_accuracy: 0.7648 - val_loss: 0.4998\n",
      "Epoch 3/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 99ms/step - accuracy: 0.7805 - loss: 0.4808 - val_accuracy: 0.7648 - val_loss: 0.4943\n",
      "Epoch 4/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.7687 - loss: 0.4926 - val_accuracy: 0.7688 - val_loss: 0.4909\n",
      "Epoch 5/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.7793 - loss: 0.4766 - val_accuracy: 0.7727 - val_loss: 0.4875\n",
      "Epoch 6/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.7805 - loss: 0.4973 - val_accuracy: 0.7747 - val_loss: 0.4862\n",
      "Epoch 7/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.7734 - loss: 0.4867 - val_accuracy: 0.7708 - val_loss: 0.5014\n",
      "Epoch 8/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.7752 - loss: 0.4719 - val_accuracy: 0.7628 - val_loss: 0.4887\n",
      "Epoch 9/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.7676 - loss: 0.4939 - val_accuracy: 0.7787 - val_loss: 0.4861\n",
      "Epoch 10/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.7746 - loss: 0.4759 - val_accuracy: 0.7846 - val_loss: 0.4834\n",
      "Epoch 11/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.7799 - loss: 0.4561 - val_accuracy: 0.8360 - val_loss: 0.3958\n",
      "Epoch 12/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - accuracy: 0.8875 - loss: 0.3083 - val_accuracy: 0.8715 - val_loss: 0.2888\n",
      "Epoch 13/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.9024 - loss: 0.2507 - val_accuracy: 0.9051 - val_loss: 0.2429\n",
      "Epoch 14/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 98ms/step - accuracy: 0.9010 - loss: 0.2563 - val_accuracy: 0.9111 - val_loss: 0.2312\n",
      "Epoch 15/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.9172 - loss: 0.2124 - val_accuracy: 0.9071 - val_loss: 0.2304\n",
      "Epoch 16/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.9105 - loss: 0.2266 - val_accuracy: 0.9130 - val_loss: 0.2288\n",
      "Epoch 17/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.9245 - loss: 0.2241 - val_accuracy: 0.9130 - val_loss: 0.2307\n",
      "Epoch 18/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9358 - loss: 0.1956 - val_accuracy: 0.9170 - val_loss: 0.2345\n",
      "Epoch 19/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9293 - loss: 0.2174 - val_accuracy: 0.9091 - val_loss: 0.2379\n",
      "Epoch 20/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.9320 - loss: 0.2080 - val_accuracy: 0.9150 - val_loss: 0.2393\n",
      "Epoch 21/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9408 - loss: 0.1947 - val_accuracy: 0.9091 - val_loss: 0.2388\n",
      "Epoch 22/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.9438 - loss: 0.1882 - val_accuracy: 0.9130 - val_loss: 0.2469\n",
      "Epoch 23/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.9462 - loss: 0.1861 - val_accuracy: 0.9130 - val_loss: 0.2480\n",
      "Epoch 24/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 0.9336 - loss: 0.2064 - val_accuracy: 0.9051 - val_loss: 0.2527\n",
      "Epoch 25/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.9406 - loss: 0.1913 - val_accuracy: 0.9091 - val_loss: 0.2579\n",
      "Epoch 26/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.9453 - loss: 0.1773 - val_accuracy: 0.9032 - val_loss: 0.2604\n",
      "Epoch 27/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9365 - loss: 0.1891 - val_accuracy: 0.9071 - val_loss: 0.2674\n",
      "Epoch 28/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.9404 - loss: 0.1936 - val_accuracy: 0.8972 - val_loss: 0.2856\n",
      "Epoch 29/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9433 - loss: 0.1824 - val_accuracy: 0.9111 - val_loss: 0.2740\n",
      "Epoch 30/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9369 - loss: 0.1932 - val_accuracy: 0.9051 - val_loss: 0.2832\n",
      "Epoch 31/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.9436 - loss: 0.1890 - val_accuracy: 0.8972 - val_loss: 0.2933\n",
      "Epoch 32/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - accuracy: 0.9417 - loss: 0.1822 - val_accuracy: 0.9032 - val_loss: 0.2864\n",
      "Epoch 33/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.9501 - loss: 0.1723 - val_accuracy: 0.9032 - val_loss: 0.2900\n",
      "Epoch 34/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.9483 - loss: 0.1711 - val_accuracy: 0.9071 - val_loss: 0.2884\n",
      "Epoch 35/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9556 - loss: 0.1544 - val_accuracy: 0.9051 - val_loss: 0.2919\n",
      "Epoch 36/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.9498 - loss: 0.1664 - val_accuracy: 0.9012 - val_loss: 0.3186\n",
      "Epoch 37/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9577 - loss: 0.1524 - val_accuracy: 0.9032 - val_loss: 0.3043\n",
      "Epoch 38/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9432 - loss: 0.1713 - val_accuracy: 0.8992 - val_loss: 0.3142\n",
      "Epoch 39/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.9449 - loss: 0.1698 - val_accuracy: 0.8953 - val_loss: 0.3158\n",
      "Epoch 40/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.9587 - loss: 0.1377 - val_accuracy: 0.8972 - val_loss: 0.3046\n",
      "Epoch 41/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.9545 - loss: 0.1560 - val_accuracy: 0.8953 - val_loss: 0.3256\n",
      "Epoch 42/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9509 - loss: 0.1663 - val_accuracy: 0.8913 - val_loss: 0.3245\n",
      "Epoch 43/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9503 - loss: 0.1640 - val_accuracy: 0.9012 - val_loss: 0.3301\n",
      "Epoch 44/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.9475 - loss: 0.1703 - val_accuracy: 0.8933 - val_loss: 0.3361\n",
      "Epoch 45/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9484 - loss: 0.1681 - val_accuracy: 0.8933 - val_loss: 0.3413\n",
      "Epoch 46/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9490 - loss: 0.1577 - val_accuracy: 0.8893 - val_loss: 0.3524\n",
      "Epoch 47/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.9598 - loss: 0.1375 - val_accuracy: 0.8874 - val_loss: 0.3387\n",
      "Epoch 48/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.9565 - loss: 0.1376 - val_accuracy: 0.8893 - val_loss: 0.3526\n",
      "Epoch 49/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.9559 - loss: 0.1463 - val_accuracy: 0.8874 - val_loss: 0.3588\n",
      "Epoch 50/50\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 91ms/step - accuracy: 0.9578 - loss: 0.1426 - val_accuracy: 0.8874 - val_loss: 0.3698\n"
     ]
    }
   ],
   "source": [
    "history = transformer.fit(train_X_vector, y_train, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "4b332066-06c8-40b8-afe8-0708852731e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = transformer.predict(test_X_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0290a635-9c22-4bd2-af4c-eb1996f33dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.915361</td>\n",
       "      <td>0.891603</td>\n",
       "      <td>319.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908784</td>\n",
       "      <td>0.859425</td>\n",
       "      <td>0.883415</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.887658</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>0.887658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.888916</td>\n",
       "      <td>0.887393</td>\n",
       "      <td>0.887509</td>\n",
       "      <td>632.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.888727</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>0.887548</td>\n",
       "      <td>632.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.869048  0.915361  0.891603  319.000000\n",
       "1              0.908784  0.859425  0.883415  313.000000\n",
       "accuracy       0.887658  0.887658  0.887658    0.887658\n",
       "macro avg      0.888916  0.887393  0.887509  632.000000\n",
       "weighted avg   0.888727  0.887658  0.887548  632.000000"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(y_test, np.round(pred), output_dict=True)\n",
    "pd.DataFrame(report).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ae80c63f-8888-413c-af99-134167c98e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876582278481012"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, np.round(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "e813e65b-f91e-4347-b0a7-cedb8658c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.save('fake_news_v1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5faac-8b99-4310-8623-cb0cbfaa6163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
